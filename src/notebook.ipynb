{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information about dateset\n",
    "- 40 000 rgb images\n",
    "- 20 000 with cracks \n",
    "- 20 000 without cracks\n",
    "- 75% of the data for training and rest for testing\n",
    "\n",
    "- cracks can be confused with background texture or noise\n",
    "- inhomogeneous illumination in pictures\n",
    "- irreguralities in cracks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"data/images\"\n",
    "negative_file_path=os.path.join(directory,\"Negative\")\n",
    "positive_file_path=os.path.join(directory,\"Positive\")\n",
    "\n",
    "print(f\"negative_file_path: {negative_file_path}\\npositive_file_path: {positive_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in  os.listdir(negative_file_path):\n",
    "    os.path.join(negative_file_path,file)\n",
    "\n",
    "for file in  os.listdir(positive_file_path):\n",
    "    os.path.join(positive_file_path,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_files = []\n",
    "for file in os.listdir(negative_file_path):\n",
    "    if file.endswith(\".jpg\"):\n",
    "        negative_files.append(os.path.join(negative_file_path,file))\n",
    "\n",
    "positive_files = []\n",
    "for file in os.listdir(positive_file_path):\n",
    "    if file.endswith(\".jpg\"):\n",
    "        positive_files.append(os.path.join(positive_file_path,file))\n",
    "\n",
    "negative_files.sort()\n",
    "positive_files.sort()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_files[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_files[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have created 2 python lists for negative and positives images, we can view them with matplotlib as seen below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image1 = Image.open(negative_files[0])\n",
    "plt.imshow(image1)\n",
    "plt.title(\"1st Image With No Cracks\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image2 = Image.open(positive_files[1])\n",
    "plt.title(\"1st Image With Crack\")\n",
    "plt.imshow(image2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing data for PyTorch\n",
    "We have to combine images into a PyTorch Dataset object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_samples = len(positive_files) + len(negative_files)\n",
    "\n",
    "Y = torch.zeros(number_of_samples)\n",
    "Y = Y.type(torch.LongTensor)\n",
    "Y[::2] = 1\n",
    "Y[1::2] = 0\n",
    "\n",
    "# Y = 1 0 1 0 1 0 1 0 ... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a simple tensor to show which image is positive(1) and negative(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = []\n",
    "\n",
    "index = 0\n",
    "for file in positive_files:\n",
    "    all_files.insert(index, file)\n",
    "    index += 2\n",
    "\n",
    "index = 1\n",
    "for file in negative_files:\n",
    "    all_files.insert(index, file)\n",
    "    index += 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_n_items(n, data):\n",
    "    for y,file in zip(Y, data[0:n]):\n",
    "        plt.imshow(Image.open(file))\n",
    "        plt.title(\"y=\"+str(y.item()))\n",
    "        plt.show()\n",
    "\n",
    "show_n_items(2, data= all_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining Data into PyTorch DataSet\n",
    "Now we can use this Dataset class to train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "\n",
    "    def __init__(self,transform,train=True):\n",
    "        directory=\"data/images\"\n",
    "        positive=\"Positive\"\n",
    "        negative=\"Negative\"\n",
    "\n",
    "        positive_file_path=os.path.join(directory,positive)\n",
    "        negative_file_path=os.path.join(directory,negative)\n",
    "\n",
    "        for file in  os.listdir(negative_file_path):\n",
    "            os.path.join(negative_file_path,file)\n",
    "\n",
    "        for file in  os.listdir(positive_file_path):\n",
    "            os.path.join(positive_file_path,file)\n",
    "\n",
    "        negative_files = []\n",
    "        for file in os.listdir(negative_file_path):\n",
    "            if file.endswith(\".jpg\"):\n",
    "                negative_files.append(os.path.join(negative_file_path,file))\n",
    "        negative_files.sort()\n",
    "\n",
    "        positive_files = []\n",
    "        for file in os.listdir(positive_file_path):\n",
    "            if file.endswith(\".jpg\"):\n",
    "                positive_files.append(os.path.join(positive_file_path,file))\n",
    "        positive_files.sort()\n",
    "\n",
    "        self.all_files = []\n",
    "        index = 0\n",
    "        for file in positive_files:\n",
    "            self.all_files.insert(index, file)\n",
    "            index += 2\n",
    "        index = 1\n",
    "        for file in negative_files:\n",
    "            self.all_files.insert(index, file)\n",
    "            index += 2\n",
    "        \n",
    "        self.Y=torch.zeros([len(self.all_files)]).type(torch.LongTensor)\n",
    "        self.Y[::2]=1\n",
    "        self.Y[1::2]=0\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "        \n",
    "        if train:\n",
    "            self.all_files = self.all_files[:30000]\n",
    "            self.Y=self.Y[:30000]\n",
    "            self.len=len(self.all_files)\n",
    "        else:\n",
    "            self.all_files = self.all_files[30000:]\n",
    "            self.Y=self.Y[30000:]\n",
    "            self.len=len(self.all_files)\n",
    "    \n",
    "  \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image=Image.open(self.all_files[idx])\n",
    "        y=self.Y[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean, std)])\n",
    "\n",
    "train_dataset = Dataset(train= True, transform= transform)\n",
    "validation_dataset = Dataset(train= False, transform= transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created 2 dataset objects for training and validation. They are transformed into a tensor and normalized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Classifier with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax(nn.Module):\n",
    "    def __init__(self, input_size, out_size):\n",
    "        super(Softmax, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, out_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_of_image=3*227*227 \n",
    "\n",
    "model = Softmax(size_of_image, 2)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum= 0.1)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_loader = torch.utils.data.DataLoader(train_dataset, batch_size=5)\n",
    "validation_dataset_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created model the optimizer, loss function, data loaders and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs=5\n",
    "\n",
    "accuracy_list=[]\n",
    "N_test=len(validation_dataset)\n",
    "\n",
    "def train_model(n_epochs):\n",
    "    for epoch in range(n_epochs):\n",
    "        for x, y in train_dataset_loader:\n",
    "            optimizer.zero_grad()\n",
    "            z = model(x.view(-1, size_of_image))\n",
    "            loss = criterion(z, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        correct=0\n",
    "        for x_test, y_test in validation_dataset_loader:\n",
    "            z = model(x_test.view(-1, size_of_image))\n",
    "            _, yhat = torch.max(z.data, 1)\n",
    "            correct += (yhat == y_test).sum().item()\n",
    "        accuracy = correct / N_test\n",
    "        accuracy_list.append(accuracy)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_model(n_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple function to train the model with n epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model.state_dict(),'model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'model.pt'\n",
    "model = torch.load(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving and loading the trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using a pretrained PyTorch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model = models.resnet18(pretrained= True)\n",
    "\n",
    "composed_transform = transforms.Compose([transforms.Resize(224), transforms.ToTensor(), transforms.Normalize(mean, std)])\n",
    "\n",
    "# we will only change the last layer of the pretrained model\n",
    "for param in pretrained_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "pretrained_model.fc = nn.Linear(512, 2)\n",
    "\n",
    "pretrained_model_optimizer = torch.optim.Adam([parameters for parameters in pretrained_model.parameters() if parameters.requires_grad], lr=0.003)\n",
    "# criterion, dataset loaders are the same "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "function to train the output of pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs2 = 5\n",
    "loss_list2 = []\n",
    "accuracy_list2 = []\n",
    "correct2 = 0\n",
    "n_test2 = len(validation_dataset)\n",
    "\n",
    "def train_pretrained_model():\n",
    "    loss_sublist = []\n",
    "    for epoch in range(n_epochs2):\n",
    "        print(f'Epoch {epoch+1}/{n_epochs2}')\n",
    "        for x, y in train_dataset_loader:\n",
    "            pretrained_model.train()\n",
    "            optimizer.zero_grad()\n",
    "            z = pretrained_model(x)\n",
    "            loss = criterion(z, y)\n",
    "            loss_sublist.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        loss_list2.append(np.mean(loss_sublist))\n",
    "\n",
    "        correct2 = 0\n",
    "        for x_test, y_test in validation_dataset_loader:\n",
    "            pretrained_model.eval()\n",
    "            z = model(x_test)\n",
    "            _, yhat = torch.max(z.data, 1)\n",
    "            correct2 += (yhat == y_test).sum().item()\n",
    "            accuracy = correct2 / n_test2\n",
    "            accuracy_list2.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pretrained_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(pretrained_model.state_dict(),'model2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_path2 = 'model2.pt'\n",
    "#spretrained_model = torch.load(model_path2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
